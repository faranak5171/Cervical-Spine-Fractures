{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Place Solution Training 3D Semantic Segmentation (Stage1)\n",
    "\n",
    "Hi all,\n",
    "\n",
    "I'm very exciting to writing this notebook and the summary of our solution here.\n",
    "\n",
    "This is FULL version of training my final models (stage1), using resnet18d as backbone, unet as decoder and using 128x128x128 as input.\n",
    "\n",
    "NOTE: **You need to run this code locally because the RAM is not enough here.**\n",
    "\n",
    "NOTE2: **It is highly recommended to pre-process the 3D semantic segmentation training data first and save it locally, which can greatly speed up the loading of the data.**\n",
    "\n",
    "My brief summary of winning solution: https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/362607\n",
    "\n",
    "* Train Stage1 Notebook: This notebook\n",
    "* Train Stage2 (Type1) Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage2-type1\n",
    "* Train Stage2 (Type2) Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage2-type2\n",
    "* Inference Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-inference\n",
    "\n",
    "**If you find these notebooks helpful please upvote. Thanks! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T05:59:39.369783Z",
     "iopub.status.busy": "2022-10-29T05:59:39.369067Z",
     "iopub.status.idle": "2022-10-29T06:00:25.730464Z",
     "shell.execute_reply": "2022-10-29T06:00:25.729271Z",
     "shell.execute_reply.started": "2022-10-29T05:59:39.369678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement '../input/pylibjpeg140py3/pylibjpeg-1.4.0-py3-none-any.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Faranak\\\\Documents\\\\Courses\\\\Thesis\\\\RSNA-2022-cervical-spine-fracture-detection\\\\input\\\\pylibjpeg140py3\\\\pylibjpeg-1.4.0-py3-none-any.whl'\n",
      "\n",
      "WARNING: Requirement '../input/pylibjpeg140py3/python_gdcm-3.0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl' looks like a filename, but the file does not exist\n",
      "ERROR: python_gdcm-3.0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl is not a supported wheel on this platform.\n"
     ]
    }
   ],
   "source": [
    "!pip -q install monai\n",
    "!pip -q install segmentation-models-pytorch==0.2.1\n",
    "\n",
    "!pip -q install ../input/pylibjpeg140py3/pylibjpeg-1.4.0-py3-none-any.whl\n",
    "!pip -q install ../input/pylibjpeg140py3/python_gdcm-3.0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:25.733795Z",
     "iopub.status.busy": "2022-10-29T06:00:25.733350Z",
     "iopub.status.idle": "2022-10-29T06:00:25.741619Z",
     "shell.execute_reply": "2022-10-29T06:00:25.740579Z",
     "shell.execute_reply.started": "2022-10-29T06:00:25.733741Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path = [\n",
    "    '../input/covn3d-same',\n",
    "    '../input/timm20221011/pytorch-image-models-master',\n",
    "    '../input/smp20210127/segmentation_models.pytorch-master/segmentation_models.pytorch-master',\n",
    "    '../input/smp20210127/pretrained-models.pytorch-master/pretrained-models.pytorch-master',\n",
    "    '../input/smp20210127/EfficientNet-PyTorch-master/EfficientNet-PyTorch-master',\n",
    "] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:25.743219Z",
     "iopub.status.busy": "2022-10-29T06:00:25.742950Z",
     "iopub.status.idle": "2022-10-29T06:00:34.162024Z",
     "shell.execute_reply": "2022-10-29T06:00:34.160905Z",
     "shell.execute_reply.started": "2022-10-29T06:00:25.743184Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import ast\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from monai.transforms import Resize\n",
    "import  monai.transforms as transforms\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:29.485211Z",
     "iopub.status.busy": "2022-10-29T06:03:29.484820Z",
     "iopub.status.idle": "2022-10-29T06:03:29.494317Z",
     "shell.execute_reply": "2022-10-29T06:03:29.493294Z",
     "shell.execute_reply.started": "2022-10-29T06:03:29.485168Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_type = 'timm3d_res18d_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_bs4_lr3e4_20x50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "n_blocks = 4\n",
    "n_folds = 5\n",
    "backbone = 'resnet18d'\n",
    "\n",
    "image_sizes = [128, 128, 128]\n",
    "R = Resize(image_sizes)\n",
    "\n",
    "init_lr = 3e-3\n",
    "batch_size = 4\n",
    "drop_rate = 0.\n",
    "drop_path_rate = 0.\n",
    "loss_weights = [1, 1]\n",
    "p_mixup = 0.1\n",
    "\n",
    "data_dir = '../data'\n",
    "use_amp = True\n",
    "num_workers = 4\n",
    "out_dim = 7\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.390438Z",
     "iopub.status.busy": "2022-10-29T06:00:34.389599Z",
     "iopub.status.idle": "2022-10-29T06:00:34.402322Z",
     "shell.execute_reply": "2022-10-29T06:00:34.401400Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.390400Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=1),\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=2),\n",
    "    transforms.RandAffined(keys=[\"image\", \"mask\"], translate_range=[int(x*y) for x, y in zip(image_sizes, [0.3, 0.3, 0.3])], padding_mode='zeros', prob=0.7),\n",
    "    transforms.RandGridDistortiond(keys=(\"image\", \"mask\"), prob=0.5, distort_limit=(-0.01, 0.01), mode=\"nearest\"),    \n",
    "])\n",
    "\n",
    "transforms_valid = transforms.Compose([\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.404497Z",
     "iopub.status.busy": "2022-10-29T06:00:34.403952Z",
     "iopub.status.idle": "2022-10-29T06:00:34.486417Z",
     "shell.execute_reply": "2022-10-29T06:00:34.485281Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.404459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>mask_file</th>\n",
       "      <th>image_folder</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.2.826.0.1.3680043.32071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../data\\segmentations\\1.2.826.0.1.3680043.3207...</td>\n",
       "      <td>../data\\train_images\\1.2.826.0.1.3680043.32071</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.2.826.0.1.3680043.30524</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../data\\segmentations\\1.2.826.0.1.3680043.3052...</td>\n",
       "      <td>../data\\train_images\\1.2.826.0.1.3680043.30524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.2.826.0.1.3680043.28025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data\\segmentations\\1.2.826.0.1.3680043.2802...</td>\n",
       "      <td>../data\\train_images\\1.2.826.0.1.3680043.28025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.2.826.0.1.3680043.21321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../data\\segmentations\\1.2.826.0.1.3680043.2132...</td>\n",
       "      <td>../data\\train_images\\1.2.826.0.1.3680043.21321</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.2.826.0.1.3680043.26990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../data\\segmentations\\1.2.826.0.1.3680043.2699...</td>\n",
       "      <td>../data\\train_images\\1.2.826.0.1.3680043.26990</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
       "82  1.2.826.0.1.3680043.32071                1   0   1   0   1   0   1   1   \n",
       "83  1.2.826.0.1.3680043.30524                1   0   0   0   0   0   1   1   \n",
       "84  1.2.826.0.1.3680043.28025                0   0   0   0   0   0   0   0   \n",
       "85  1.2.826.0.1.3680043.21321                1   1   1   1   0   0   0   1   \n",
       "86  1.2.826.0.1.3680043.26990                1   0   0   0   0   1   1   1   \n",
       "\n",
       "                                            mask_file  \\\n",
       "82  ../data\\segmentations\\1.2.826.0.1.3680043.3207...   \n",
       "83  ../data\\segmentations\\1.2.826.0.1.3680043.3052...   \n",
       "84  ../data\\segmentations\\1.2.826.0.1.3680043.2802...   \n",
       "85  ../data\\segmentations\\1.2.826.0.1.3680043.2132...   \n",
       "86  ../data\\segmentations\\1.2.826.0.1.3680043.2699...   \n",
       "\n",
       "                                      image_folder  fold  \n",
       "82  ../data\\train_images\\1.2.826.0.1.3680043.32071     4  \n",
       "83  ../data\\train_images\\1.2.826.0.1.3680043.30524     4  \n",
       "84  ../data\\train_images\\1.2.826.0.1.3680043.28025     4  \n",
       "85  ../data\\train_images\\1.2.826.0.1.3680043.21321     4  \n",
       "86  ../data\\train_images\\1.2.826.0.1.3680043.26990     4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "\n",
    "mask_files = os.listdir(f'{data_dir}/segmentations')\n",
    "df_mask = pd.DataFrame({\n",
    "    'mask_file': mask_files,\n",
    "})\n",
    "df_mask['StudyInstanceUID'] = df_mask['mask_file'].apply(lambda x: x[:-4])\n",
    "df_mask['mask_file'] = df_mask['mask_file'].apply(lambda x: os.path.join(data_dir, 'segmentations', x))\n",
    "df = df_train.merge(df_mask, on='StudyInstanceUID', how='left')\n",
    "df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(data_dir, 'train_images', x))\n",
    "df['mask_file'].fillna('', inplace=True)\n",
    "\n",
    "df_seg = df.query('mask_file != \"\"').reset_index(drop=True)\n",
    "\n",
    "kf = KFold(5)\n",
    "df_seg['fold'] = -1\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(df_seg, df_seg)):\n",
    "    df_seg.loc[valid_idx, 'fold'] = fold\n",
    "\n",
    "df_seg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.488463Z",
     "iopub.status.busy": "2022-10-29T06:00:34.488061Z",
     "iopub.status.idle": "2022-10-29T06:00:34.494025Z",
     "shell.execute_reply": "2022-10-29T06:00:34.492953Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.488426Z"
    }
   },
   "outputs": [],
   "source": [
    "revert_list = [\n",
    "    '1.2.826.0.1.3680043.1363',\n",
    "    '1.2.826.0.1.3680043.20120',\n",
    "    '1.2.826.0.1.3680043.2243',\n",
    "    '1.2.826.0.1.3680043.24606',\n",
    "    '1.2.826.0.1.3680043.32071'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.497353Z",
     "iopub.status.busy": "2022-10-29T06:00:34.496904Z",
     "iopub.status.idle": "2022-10-29T06:00:34.514198Z",
     "shell.execute_reply": "2022-10-29T06:00:34.513162Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.497317Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (image_sizes[0], image_sizes[1]), interpolation = cv2.INTER_LINEAR)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_line_par(path):\n",
    "\n",
    "    t_paths = sorted(glob(os.path.join(path, \"*\")),\n",
    "       key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "\n",
    "    n_scans = len(t_paths)\n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., image_sizes[2])).round().astype(int)\n",
    "    t_paths = [t_paths[i] for i in indices]\n",
    "\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, -1)\n",
    "    \n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_sample(row, has_mask=True):\n",
    "\n",
    "    image = load_dicom_line_par(row.image_folder)\n",
    "    if image.ndim < 4:\n",
    "        image = np.expand_dims(image, 0).repeat(3, 0)  # to 3ch\n",
    "\n",
    "    if has_mask:\n",
    "        mask_org = nib.load(row.mask_file).get_fdata()\n",
    "        shape = mask_org.shape\n",
    "        mask_org = mask_org.transpose(1, 0, 2)[::-1, :, ::-1]  # (d, w, h)\n",
    "        mask = np.zeros((7, shape[0], shape[1], shape[2]))\n",
    "        for cid in range(7):\n",
    "            mask[cid] = (mask_org == (cid+1))\n",
    "        mask = mask.astype(np.uint8) * 255\n",
    "        mask = R(mask).numpy()\n",
    "        \n",
    "        return image, mask\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "class SEGDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        \n",
    "        ### using local cache\n",
    "#         image_file = os.path.join(data_dir, f'{row.StudyInstanceUID}.npy')\n",
    "#         mask_file = os.path.join(data_dir, f'{row.StudyInstanceUID}_mask.npy')\n",
    "#         image = np.load(image_file).astype(np.float32)\n",
    "#         mask = np.load(mask_file).astype(np.float32)\n",
    "\n",
    "        image, mask = load_sample(row, has_mask=True)\n",
    "    \n",
    "        if row.StudyInstanceUID in revert_list:\n",
    "            mask = mask[:, :, :, ::-1]\n",
    "\n",
    "        res = self.transform({'image':image, 'mask':mask})\n",
    "        image = res['image'] / 255.\n",
    "        mask = res['mask']\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "\n",
    "        image, mask = torch.tensor(image).float(), torch.tensor(mask).float()\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.516237Z",
     "iopub.status.busy": "2022-10-29T06:00:34.515883Z",
     "iopub.status.idle": "2022-10-29T06:00:34.528793Z",
     "shell.execute_reply": "2022-10-29T06:00:34.527571Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.516189Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "df_show = df_seg\n",
    "dataset_show = SEGDataset(df_show, 'train', transform=transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:00:34.533948Z",
     "iopub.status.busy": "2022-10-29T06:00:34.533491Z",
     "iopub.status.idle": "2022-10-29T06:02:59.056109Z",
     "shell.execute_reply": "2022-10-29T06:02:59.055183Z",
     "shell.execute_reply.started": "2022-10-29T06:00:34.533918Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m      4\u001b[0m     idx \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m+\u001b[39mp\n\u001b[1;32m----> 5\u001b[0m     img, mask \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_show\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m img[:, :, :, \u001b[38;5;241m60\u001b[39m]\n\u001b[0;32m      7\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[:, :, :, \u001b[38;5;241m60\u001b[39m]\n",
      "Cell \u001b[1;32mIn[27], line 71\u001b[0m, in \u001b[0;36mSEGDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     62\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[index]\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;66;03m### using local cache\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#         image_file = os.path.join(data_dir, f'{row.StudyInstanceUID}.npy')\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#         mask_file = os.path.join(data_dir, f'{row.StudyInstanceUID}_mask.npy')\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#         image = np.load(image_file).astype(np.float32)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#         mask = np.load(mask_file).astype(np.float32)\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m         image, mask \u001b[38;5;241m=\u001b[39m \u001b[43mload_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mStudyInstanceUID \u001b[38;5;129;01min\u001b[39;00m revert_list:\n\u001b[0;32m     74\u001b[0m             mask \u001b[38;5;241m=\u001b[39m mask[:, :, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[27], line 31\u001b[0m, in \u001b[0;36mload_sample\u001b[1;34m(row, has_mask)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sample\u001b[39m(row, has_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 31\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mload_dicom_line_par\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     33\u001b[0m         image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# to 3ch\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m, in \u001b[0;36mload_dicom_line_par\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     10\u001b[0m t_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     11\u001b[0m    key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     13\u001b[0m n_scans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(t_paths)\n\u001b[1;32m---> 14\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_scans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     15\u001b[0m t_paths \u001b[38;5;241m=\u001b[39m [t_paths[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m     17\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mquantile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4412\u001b[0m, in \u001b[0;36mquantile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4413\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4424\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4417\u001b[0m                         q,\n\u001b[0;32m   4418\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4421\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4422\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4423\u001b[0m     \u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4424\u001b[0m     r, k \u001b[38;5;241m=\u001b[39m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4425\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4426\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4427\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4428\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4429\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4430\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[0;32m   4432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mreshape(q\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m k)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3725\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3723\u001b[0m     keepdim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m-> 3725\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4593\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4591\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4592\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4593\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4594\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4595\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4596\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4597\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4699\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4691\u001b[0m arr\u001b[38;5;241m.\u001b[39mpartition(\n\u001b[0;32m   4692\u001b[0m     np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   4693\u001b[0m                               previous_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4694\u001b[0m                               next_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4695\u001b[0m                               ))),\n\u001b[0;32m   4696\u001b[0m     axis\u001b[38;5;241m=\u001b[39mDATA_AXIS)\n\u001b[0;32m   4697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[0;32m   4698\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(\n\u001b[1;32m-> 4699\u001b[0m         \u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_AXIS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4700\u001b[0m     )\n\u001b[0;32m   4701\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4702\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:190\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_take_dispatcher)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtake\u001b[39m(a, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Take elements from an array along an axis.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m           [5, 7]])\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1,4)\n",
    "    for p in range(4):\n",
    "        idx = i*4+p\n",
    "        img, mask = dataset_show[idx]\n",
    "        img = img[:, :, :, 60]\n",
    "        mask = mask[:, :, :, 60]\n",
    "        mask[0] = mask[0] + mask[3] + mask[6]\n",
    "        mask[1] = mask[1] + mask[4]\n",
    "        mask[2] = mask[2] + mask[5]\n",
    "        mask = mask[:3]\n",
    "        img = img * 0.7 + mask * 0.3\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:02:59.059903Z",
     "iopub.status.busy": "2022-10-29T06:02:59.058663Z",
     "iopub.status.idle": "2022-10-29T06:02:59.070787Z",
     "shell.execute_reply": "2022-10-29T06:02:59.069705Z",
     "shell.execute_reply.started": "2022-10-29T06:02:59.059860Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], out_dim, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:02:59.073051Z",
     "iopub.status.busy": "2022-10-29T06:02:59.072642Z",
     "iopub.status.idle": "2022-10-29T06:03:13.720715Z",
     "shell.execute_reply": "2022-10-29T06:03:13.719595Z",
     "shell.execute_reply.started": "2022-10-29T06:02:59.073017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 128, 128, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.models.layers.conv2d_same import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "\n",
    "\n",
    "def convert_3d(module):\n",
    "\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "\n",
    "\n",
    "m = TimmSegModel(backbone)\n",
    "m = convert_3d(m)\n",
    "m(torch.rand(1, 3, 128,128,128)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:13.724951Z",
     "iopub.status.busy": "2022-10-29T06:03:13.724580Z",
     "iopub.status.idle": "2022-10-29T06:03:13.736570Z",
     "shell.execute_reply": "2022-10-29T06:03:13.735400Z",
     "shell.execute_reply.started": "2022-10-29T06:03:13.724920Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "\n",
    "def binary_dice_score(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    threshold: Optional[float] = None,\n",
    "    nan_score_on_empty=False,\n",
    "    eps: float = 1e-7,\n",
    ") -> float:\n",
    "\n",
    "    if threshold is not None:\n",
    "        y_pred = (y_pred > threshold).to(y_true.dtype)\n",
    "\n",
    "    intersection = torch.sum(y_pred * y_true).item()\n",
    "    cardinality = (torch.sum(y_pred) + torch.sum(y_true)).item()\n",
    "\n",
    "    score = (2.0 * intersection) / (cardinality + eps)\n",
    "\n",
    "    has_targets = torch.sum(y_true) > 0\n",
    "    has_predicted = torch.sum(y_pred) > 0\n",
    "\n",
    "    if not has_targets:\n",
    "        if nan_score_on_empty:\n",
    "            score = np.nan\n",
    "        else:\n",
    "            score = float(not has_predicted)\n",
    "    return score\n",
    "\n",
    "\n",
    "def multilabel_dice_score(\n",
    "    y_true: torch.Tensor,\n",
    "    y_pred: torch.Tensor,\n",
    "    threshold=None,\n",
    "    eps=1e-7,\n",
    "    nan_score_on_empty=False,\n",
    "):\n",
    "    ious = []\n",
    "    num_classes = y_pred.size(0)\n",
    "    for class_index in range(num_classes):\n",
    "        iou = binary_dice_score(\n",
    "            y_pred=y_pred[class_index],\n",
    "            y_true=y_true[class_index],\n",
    "            threshold=threshold,\n",
    "            nan_score_on_empty=nan_score_on_empty,\n",
    "            eps=eps,\n",
    "        )\n",
    "        ious.append(iou)\n",
    "\n",
    "    return ious\n",
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return 1 - ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "def bce_dice(input, target, loss_weights=loss_weights):\n",
    "    loss1 = loss_weights[0] * nn.BCEWithLogitsLoss()(input, target)\n",
    "    loss2 = loss_weights[1] * dice_loss(input, target)\n",
    "    return (loss1 + loss2) / sum(loss_weights)\n",
    "\n",
    "criterion = bce_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Valid func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:13.738907Z",
     "iopub.status.busy": "2022-10-29T06:03:13.738511Z",
     "iopub.status.idle": "2022-10-29T06:03:13.755925Z",
     "shell.execute_reply": "2022-10-29T06:03:13.755044Z",
     "shell.execute_reply.started": "2022-10-29T06:03:13.738871Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, gt_masks in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        gt_masks = gt_masks.cuda()\n",
    "\n",
    "        do_mixup = False\n",
    "        if random.random() < 0.1:\n",
    "            do_mixup = True\n",
    "            images, gt_masks, gt_masks_sfl, lam = mixup(images, gt_masks)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            if do_mixup:\n",
    "                loss2 = criterion(logits, gt_masks_sfl)\n",
    "                loss = loss * lam  + loss2 * (1 - lam)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bar.set_description(f'smth:{np.mean(train_loss[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    outputs = []\n",
    "    ths = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    batch_metrics = [[]] * 7\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in bar:\n",
    "            images = images.cuda()\n",
    "            gt_masks = gt_masks.cuda()\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            valid_loss.append(loss.item())\n",
    "            for thi, th in enumerate(ths):\n",
    "                pred = (logits.sigmoid() > th).float().detach()\n",
    "                for i in range(logits.shape[0]):\n",
    "                    tmp = multilabel_dice_score(\n",
    "                        y_pred=logits[i].sigmoid().cpu(),\n",
    "                        y_true=gt_masks[i].cpu(),\n",
    "                        threshold=0.5,\n",
    "                    )\n",
    "                    batch_metrics[thi].extend(tmp)\n",
    "            bar.set_description(f'smth:{np.mean(valid_loss[-30:]):.4f}')\n",
    "            \n",
    "    metrics = [np.mean(this_metric) for this_metric in batch_metrics]\n",
    "    print('best th:', ths[np.argmax(metrics)], 'best dc:', np.max(metrics))\n",
    "\n",
    "    return np.mean(valid_loss), np.max(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:13.757646Z",
     "iopub.status.busy": "2022-10-29T06:03:13.757188Z",
     "iopub.status.idle": "2022-10-29T06:03:13.977069Z",
     "shell.execute_reply": "2022-10-29T06:03:13.976109Z",
     "shell.execute_reply.started": "2022-10-29T06:03:13.757610Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(\u001b[43mm\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39minit_lr)\n\u001b[0;32m      3\u001b[0m scheduler_cosine \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      4\u001b[0m lrs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 20, 2\n",
    "optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000)\n",
    "lrs = []\n",
    "for epoch in range(1, 1000+1):\n",
    "    scheduler_cosine.step(epoch-1)\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:13.979257Z",
     "iopub.status.busy": "2022-10-29T06:03:13.978679Z",
     "iopub.status.idle": "2022-10-29T06:03:13.992437Z",
     "shell.execute_reply": "2022-10-29T06:03:13.991378Z",
     "shell.execute_reply.started": "2022-10-29T06:03:13.979202Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "    print(log_file)\n",
    "    train_ = df_seg[df_seg['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df_seg[df_seg['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = SEGDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = SEGDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmSegModel(backbone, pretrained=True)\n",
    "    model = convert_3d(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    from_epoch = 0\n",
    "    metric_best = 0.\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss, metric = valid_func(model, loader_valid)\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric > metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T06:03:33.006143Z",
     "iopub.status.busy": "2022-10-29T06:03:33.005515Z"
    }
   },
   "outputs": [],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
